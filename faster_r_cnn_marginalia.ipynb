{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2 as cv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image, ImageDraw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/everything-about-fasterrcnn-6d758f5a6d79\n",
    "# https://www.kaggle.com/code/dipam7/wheat-head-classification/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>number</th>\n",
       "      <th>jsonname</th>\n",
       "      <th>photoname</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmin_scaled</th>\n",
       "      <th>xmax_scaled</th>\n",
       "      <th>ymin_scaled</th>\n",
       "      <th>ymax_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1150</td>\n",
       "      <td>194032</td>\n",
       "      <td>/Users/imchengliang/Downloads/DS-Project/json-...</td>\n",
       "      <td>/Users/imchengliang/Downloads/DS-Project/photo...</td>\n",
       "      <td>2688</td>\n",
       "      <td>3911</td>\n",
       "      <td>m</td>\n",
       "      <td>580.707317</td>\n",
       "      <td>731.707317</td>\n",
       "      <td>785.585366</td>\n",
       "      <td>892.682927</td>\n",
       "      <td>108.018474</td>\n",
       "      <td>146.128230</td>\n",
       "      <td>65.481350</td>\n",
       "      <td>79.887247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1151</td>\n",
       "      <td>194032</td>\n",
       "      <td>/Users/imchengliang/Downloads/DS-Project/json-...</td>\n",
       "      <td>/Users/imchengliang/Downloads/DS-Project/photo...</td>\n",
       "      <td>2688</td>\n",
       "      <td>3911</td>\n",
       "      <td>m</td>\n",
       "      <td>561.195122</td>\n",
       "      <td>1219.512195</td>\n",
       "      <td>663.634146</td>\n",
       "      <td>1329.268293</td>\n",
       "      <td>104.388974</td>\n",
       "      <td>123.443852</td>\n",
       "      <td>109.135584</td>\n",
       "      <td>118.957786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>990</td>\n",
       "      <td>184970</td>\n",
       "      <td>/Users/imchengliang/Downloads/DS-Project/json-...</td>\n",
       "      <td>/Users/imchengliang/Downloads/DS-Project/photo...</td>\n",
       "      <td>3366</td>\n",
       "      <td>4866</td>\n",
       "      <td>m</td>\n",
       "      <td>2525.969697</td>\n",
       "      <td>2348.484848</td>\n",
       "      <td>2944.151515</td>\n",
       "      <td>2627.272727</td>\n",
       "      <td>375.218315</td>\n",
       "      <td>437.336826</td>\n",
       "      <td>168.921023</td>\n",
       "      <td>188.973583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>991</td>\n",
       "      <td>184970</td>\n",
       "      <td>/Users/imchengliang/Downloads/DS-Project/json-...</td>\n",
       "      <td>/Users/imchengliang/Downloads/DS-Project/photo...</td>\n",
       "      <td>3366</td>\n",
       "      <td>4866</td>\n",
       "      <td>m</td>\n",
       "      <td>2604.757576</td>\n",
       "      <td>2969.696970</td>\n",
       "      <td>3016.878788</td>\n",
       "      <td>3287.878788</td>\n",
       "      <td>386.921803</td>\n",
       "      <td>448.140046</td>\n",
       "      <td>213.603358</td>\n",
       "      <td>236.489432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>992</td>\n",
       "      <td>184970</td>\n",
       "      <td>/Users/imchengliang/Downloads/DS-Project/json-...</td>\n",
       "      <td>/Users/imchengliang/Downloads/DS-Project/photo...</td>\n",
       "      <td>3366</td>\n",
       "      <td>4866</td>\n",
       "      <td>m</td>\n",
       "      <td>1695.666667</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2235.060606</td>\n",
       "      <td>2627.272727</td>\n",
       "      <td>251.881561</td>\n",
       "      <td>332.005438</td>\n",
       "      <td>179.819153</td>\n",
       "      <td>188.973583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  number                                           jsonname  \\\n",
       "0        1150  194032  /Users/imchengliang/Downloads/DS-Project/json-...   \n",
       "1        1151  194032  /Users/imchengliang/Downloads/DS-Project/json-...   \n",
       "2         990  184970  /Users/imchengliang/Downloads/DS-Project/json-...   \n",
       "3         991  184970  /Users/imchengliang/Downloads/DS-Project/json-...   \n",
       "4         992  184970  /Users/imchengliang/Downloads/DS-Project/json-...   \n",
       "\n",
       "                                           photoname  width  height class  \\\n",
       "0  /Users/imchengliang/Downloads/DS-Project/photo...   2688    3911     m   \n",
       "1  /Users/imchengliang/Downloads/DS-Project/photo...   2688    3911     m   \n",
       "2  /Users/imchengliang/Downloads/DS-Project/photo...   3366    4866     m   \n",
       "3  /Users/imchengliang/Downloads/DS-Project/photo...   3366    4866     m   \n",
       "4  /Users/imchengliang/Downloads/DS-Project/photo...   3366    4866     m   \n",
       "\n",
       "          xmin         ymin         xmax         ymax  xmin_scaled  \\\n",
       "0   580.707317   731.707317   785.585366   892.682927   108.018474   \n",
       "1   561.195122  1219.512195   663.634146  1329.268293   104.388974   \n",
       "2  2525.969697  2348.484848  2944.151515  2627.272727   375.218315   \n",
       "3  2604.757576  2969.696970  3016.878788  3287.878788   386.921803   \n",
       "4  1695.666667  2500.000000  2235.060606  2627.272727   251.881561   \n",
       "\n",
       "   xmax_scaled  ymin_scaled  ymax_scaled  \n",
       "0   146.128230    65.481350    79.887247  \n",
       "1   123.443852   109.135584   118.957786  \n",
       "2   437.336826   168.921023   188.973583  \n",
       "3   448.140046   213.603358   236.489432  \n",
       "4   332.005438   179.819153   188.973583  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes = pd.read_csv(\"rescaled_data.csv\")\n",
    "boxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>xmin_scaled</th>\n",
       "      <th>ymin_scaled</th>\n",
       "      <th>xmax_scaled</th>\n",
       "      <th>ymax_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194032</td>\n",
       "      <td>108.018474</td>\n",
       "      <td>65.481350</td>\n",
       "      <td>146.128230</td>\n",
       "      <td>79.887247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194032</td>\n",
       "      <td>104.388974</td>\n",
       "      <td>109.135584</td>\n",
       "      <td>123.443852</td>\n",
       "      <td>118.957786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184970</td>\n",
       "      <td>375.218315</td>\n",
       "      <td>168.921023</td>\n",
       "      <td>437.336826</td>\n",
       "      <td>188.973583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184970</td>\n",
       "      <td>386.921803</td>\n",
       "      <td>213.603358</td>\n",
       "      <td>448.140046</td>\n",
       "      <td>236.489432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184970</td>\n",
       "      <td>251.881561</td>\n",
       "      <td>179.819153</td>\n",
       "      <td>332.005438</td>\n",
       "      <td>188.973583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  xmin_scaled  ymin_scaled  xmax_scaled  ymax_scaled\n",
       "0  194032   108.018474    65.481350   146.128230    79.887247\n",
       "1  194032   104.388974   109.135584   123.443852   118.957786\n",
       "2  184970   375.218315   168.921023   437.336826   188.973583\n",
       "3  184970   386.921803   213.603358   448.140046   236.489432\n",
       "4  184970   251.881561   179.819153   332.005438   188.973583"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes = pd.read_csv(\"rescaled_data.csv\")\n",
    "boxes = boxes[[\"number\", \"xmin_scaled\", \"ymin_scaled\", \"xmax_scaled\", \"ymax_scaled\"]]\n",
    "boxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>xmin_scaled</th>\n",
       "      <th>ymin_scaled</th>\n",
       "      <th>xmax_scaled</th>\n",
       "      <th>ymax_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>184415</td>\n",
       "      <td>346.255886</td>\n",
       "      <td>125.962763</td>\n",
       "      <td>466.169443</td>\n",
       "      <td>150.890595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>184549</td>\n",
       "      <td>298.020978</td>\n",
       "      <td>205.516706</td>\n",
       "      <td>397.297561</td>\n",
       "      <td>291.958042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>186537</td>\n",
       "      <td>112.028066</td>\n",
       "      <td>177.358083</td>\n",
       "      <td>135.097020</td>\n",
       "      <td>187.276911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>186537</td>\n",
       "      <td>84.171215</td>\n",
       "      <td>268.280669</td>\n",
       "      <td>184.717035</td>\n",
       "      <td>292.841575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>186537</td>\n",
       "      <td>436.734481</td>\n",
       "      <td>226.007571</td>\n",
       "      <td>461.979752</td>\n",
       "      <td>245.845226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      number  xmin_scaled  ymin_scaled  xmax_scaled  ymax_scaled\n",
       "1703  184415   346.255886   125.962763   466.169443   150.890595\n",
       "1704  184549   298.020978   205.516706   397.297561   291.958042\n",
       "1705  186537   112.028066   177.358083   135.097020   187.276911\n",
       "1706  186537    84.171215   268.280669   184.717035   292.841575\n",
       "1707  186537   436.734481   226.007571   461.979752   245.845226"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(imageID):\n",
    "    \"\"\"reads in image and returns preprocessed np array\"\"\"\n",
    "    img = cv.imread(f\"./data/rescaled_png_files/{imageID}.png\")\n",
    "   # img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img = img/255\n",
    "    img = torch.tensor(img, dtype=torch.float32)\n",
    "    img = img.permute(2,0,1) # change channel position\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir('./data/rescaled_png_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19394'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"19394.png\"\n",
    "name.removesuffix(\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "all_box_coordinates = []\n",
    "for image in image_list:\n",
    "    image_dict = {}\n",
    "    id = image.removesuffix('.png')  \n",
    "    sub_df = boxes[boxes[\"number\"] == int(id)]\n",
    "    num_boxes = len(sub_df)\n",
    "    box_coordinates = []\n",
    "    for i in range(num_boxes):\n",
    "        sub_sub_df = sub_df.iloc[i]\n",
    "        xmin_scaled = int(sub_sub_df[\"xmin_scaled\"])\n",
    "        ymin_scaled = int(sub_sub_df[\"ymin_scaled\"])\n",
    "        xmax_scaled = int(sub_sub_df[\"xmax_scaled\"])\n",
    "        ymax_scaled = int(sub_sub_df[\"ymax_scaled\"])\n",
    "        box_coordinates.append(torch.tensor([xmin_scaled, ymin_scaled, xmax_scaled, ymax_scaled], dtype=torch.int32))\n",
    "    if num_boxes > 1:\n",
    "        box_coordinates = torch.stack(box_coordinates, axis=0)\n",
    "    else:\n",
    "        box_coordinates = box_coordinates[0]\n",
    "        box_coordinates = box_coordinates.view(1,4)\n",
    "\n",
    "    all_box_coordinates.append(box_coordinates)\n",
    "    \n",
    "    image_data = preprocessing(id) # returns list\n",
    "\n",
    "    # labels\n",
    "    labels = torch.ones(num_boxes, dtype=torch.int64)\n",
    "\n",
    "    # stack it to dict\n",
    "    image_dict[\"data\"] = image_data\n",
    "    image_dict[\"boxes\"] = box_coordinates\n",
    "    image_dict[\"labels\"] = labels\n",
    "    image_dict[\"image_id\"] = id\n",
    "\n",
    "    data.append(image_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginaliaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.n_samples = len(data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index][\"data\"]\n",
    "        boxes = self.data[index][\"boxes\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "        id = self.data[index][\"image_id\"]\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        return img, target, id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:4]\n",
    "test_data = data[len(data)-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MarginaliaDataset(train_data)\n",
    "test_dataset = MarginaliaDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img, target, \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m train_dataset[\u001b[39m13\u001b[39;49m]\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(img\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mid\u001b[39m)\n",
      "Cell \u001b[0;32mIn [16], line 7\u001b[0m, in \u001b[0;36mMarginaliaDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m----> 7\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[index][\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m     boxes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index][\u001b[39m\"\u001b[39m\u001b[39mboxes\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index][\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "img, target, id = train_dataset[13]\n",
    "print(img.shape)\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[212,  17, 259,  35],\n",
      "        [291,  19, 355,  29],\n",
      "        [ 64,  33, 458, 121],\n",
      "        [ 77, 129, 122, 148],\n",
      "        [382, 221, 441, 241],\n",
      "        [ 43, 222, 129, 251]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(target[\"boxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=4, num_workers=4, collate_fn=collate_fn, pin_memory = True)\n",
    "val_dl = DataLoader(test_dataset, batch_size=4, collate_fn=collate_fn, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = 2  # 1 class (marginalia) + background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for images, targets, _ in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "#         print(loss_dict)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        epoch_loss += losses.item()\n",
    "\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"loss for epoch {epoch}: {epoch_loss / len(train_dl)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'faster_r_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "detection_threshold = 0.5 # ???\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "for images, targets, id in val_dl:    \n",
    "\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    outputs = model(images)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "\n",
    "        boxes = outputs[i]['boxes']\n",
    "        scores = outputs[i]['scores']\n",
    "        labels = outputs[i]['labels']\n",
    "\n",
    "        keep = torchvision.ops.nms(boxes, scores, 0.1) # the lower, the less we keep\n",
    "        boxes = boxes[keep]\n",
    "        scores = scores[keep]\n",
    "        image_id = id[i]\n",
    "    \n",
    "        op = (id[i], boxes, scores)\n",
    "        results.append(op)\n",
    "\n",
    "        #break\n",
    "    #break\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(imageID, tensor_bounding_box):\n",
    "    tensor_bounding_box = tensor_bounding_box.cpu().numpy()\n",
    "    image = cv.imread(f\"data/{imageID}.png\")\n",
    "    image = np.asarray(image)\n",
    "    for box in tensor_bounding_box:\n",
    "        x_min = box[0]\n",
    "        y_min = box[1]\n",
    "        x_max = box[2]\n",
    "        y_max = box[3]\n",
    "        print(x_min)\n",
    "        \n",
    "        color = (0, 0, 255)\n",
    "        start_point = (int(x_min), int(y_min))\n",
    "        end_point = (int(x_max), int(y_max))\n",
    "        thickness = 2\n",
    "        cv.rectangle(image, start_point, end_point, color, thickness)\n",
    "    cv.imwrite(f'results/prediction_{imageID}.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m images, targets, \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m val_dl:\n\u001b[0;32m----> 2\u001b[0m     a, b \u001b[39m=\u001b[39m images\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(a)\n\u001b[1;32m      4\u001b[0m     \u001b[39m# images = list(image.to(device) for image in images)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[39m# targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\u001b[39;00m\n\u001b[1;32m      6\u001b[0m    \u001b[39m#outputs = model(images)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for images, targets, id in val_dl:\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    outputs = model(images)\n",
    "    for i, image in enumerate(images):\n",
    "        visualize_prediction(id, outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
