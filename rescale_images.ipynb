{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir('./data/image_files/')\n",
    "json_list = os.listdir('./data/json_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def png_to_np(path='./data/image_files/184127.png'):\n",
    "    \"\"\"\n",
    "    Input: .png file\n",
    "    Output: np.array\n",
    "    \"\"\"\n",
    "    # read image\n",
    "    img = cv.imread(path)\n",
    "    # convert to grayscale \n",
    "    gray_scale_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    return gray_scale_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 89,  95,  82, ..., 255, 255, 255],\n",
       "       [ 66,  72,  84, ..., 255, 255, 255],\n",
       "       [ 62,  64,  67, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 254, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_repr = png_to_np()\n",
    "np_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5010, 3342)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images\n",
    "\n",
    "# https://datascience.stackexchange.com/questions/40462/how-to-prepare-the-varied-size-input-in-cnn-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5010, 3342, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread(cv.samples.findFile(\"./data/image_files/184127.png\"))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5010, 3342)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/jonas/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "cv.imshow('Gray image', gray)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2505, 1671)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled = cv.pyrDown(gray)\n",
    "downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"image\", downsampled)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1670)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize image\n",
    "width = 1670\n",
    "height = 2500\n",
    "\n",
    "resized_image = cv.resize(downsampled, (width, height))\n",
    "resized_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min height:  4491\n",
      "min width:  1213\n"
     ]
    }
   ],
   "source": [
    "# find minimum height of images\n",
    "min_heigth = math.inf\n",
    "min_width = math.inf\n",
    "for image in image_list:\n",
    "    img = cv.imread(cv.samples.findFile(\"./data/image_files/\"+image))\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "    if img_height < min_heigth:\n",
    "        min_height = img_height\n",
    "    if img_width < min_width:\n",
    "        min_width = img_width\n",
    "print('min height: ', min_height)\n",
    "print('min width: ', min_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmin height:  4491\\nmin width:  1213\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "min height:  4491\n",
    "min width:  1213\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_image(image, width=1213, height=4491):\n",
    "    \"\"\"\n",
    "    Rescales a given image to input width and height\n",
    "    \"\"\"\n",
    "    resized_image = cv.resize(image, (width, height))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_image(image):\n",
    "    \"\"\"downsamples image (divides size by 2)\"\"\"\n",
    "    return cv.pyrDown(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(image_list):\n",
    "    image_ls = []\n",
    "    # iterate through all image paths\n",
    "    for image in image_list:\n",
    "        # gets gray scale np array representation\n",
    "        image = png_to_np(\"./data/image_files/\"+image)\n",
    "        # scale down image\n",
    "        scaled_down_img = rescale_image(image)\n",
    "        image_ls.append(scaled_down_img)\n",
    "\n",
    "    # returns np array of shape (n_images, height, width)\n",
    "    return np.stack(image_ls, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_dataset(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514, 2245, 606)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
