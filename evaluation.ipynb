{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2 as cv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import math\n",
    "\n",
    "from __future__ import division\n",
    "import scipy.optimize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginaliaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.n_samples = len(data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index][\"data\"]\n",
    "        boxes = self.data[index][\"boxes\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "        id = self.data[index][\"image_id\"]\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        return img, target, id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(imageID, path):\n",
    "    \"\"\"reads in image and returns preprocessed np array\"\"\"\n",
    "    img = cv.imread(f\"{path}{imageID}.png\")\n",
    "   # img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img = img/255\n",
    "    img = torch.tensor(img, dtype=torch.float32)\n",
    "    img = img.permute(2,0,1) # change channel position\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(image_list, box_df, image_path=\"./data/rescaled_png_files/\"):\n",
    "    data = []\n",
    "    all_box_coordinates = []\n",
    "    #print(image_list)\n",
    "    for image in image_list:\n",
    "        image_dict = {}\n",
    "        #id = image.removesuffix('.png') \n",
    "        if image.endswith(\".png\"): \n",
    "            id = image[:-4]\n",
    "        else: \n",
    "            continue\n",
    "\n",
    "        sub_df = box_df[box_df[\"number\"] == int(id)]\n",
    "        num_boxes = len(sub_df)\n",
    "        box_coordinates = []\n",
    "        for i in range(num_boxes):\n",
    "            sub_sub_df = sub_df.iloc[i]\n",
    "            xmin_scaled = int(sub_sub_df[\"xmin_scaled\"])\n",
    "            ymin_scaled = int(sub_sub_df[\"ymin_scaled\"])\n",
    "            xmax_scaled = int(sub_sub_df[\"xmax_scaled\"])\n",
    "            ymax_scaled = int(sub_sub_df[\"ymax_scaled\"])\n",
    "            box_coordinates.append(torch.tensor([xmin_scaled, ymin_scaled, xmax_scaled, ymax_scaled], dtype=torch.int32))\n",
    "        if num_boxes > 1:\n",
    "            box_coordinates = torch.stack(box_coordinates, axis=0)\n",
    "        elif num_boxes == 1:\n",
    "            box_coordinates = box_coordinates[0]\n",
    "            box_coordinates = box_coordinates.view(1,4)\n",
    "        else:\n",
    "            pass\n",
    "        all_box_coordinates.append(box_coordinates)\n",
    "        \n",
    "        image_data = preprocessing(id, image_path) # returns list\n",
    "\n",
    "        # labels\n",
    "        labels = torch.ones(num_boxes, dtype=torch.int64)\n",
    "\n",
    "        # stack it to dict\n",
    "        image_dict[\"data\"] = image_data\n",
    "        image_dict[\"boxes\"] = box_coordinates\n",
    "        image_dict[\"labels\"] = labels\n",
    "        image_dict[\"image_id\"] = id\n",
    "\n",
    "        data.append(image_dict)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://gist.github.com/AruniRC/c629c2df0e68e23aff7dcaeef87c72d4\n",
    "\n",
    "def bbox_iou(boxA, boxB):\n",
    "  # https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "\n",
    "  # Determine the (x, y)-coordinates of the intersection rectangle\n",
    "  xA = max(boxA[0], boxB[0])\n",
    "  yA = max(boxA[1], boxB[1])\n",
    "  xB = min(boxA[2], boxB[2])\n",
    "  yB = min(boxA[3], boxB[3])\n",
    "\n",
    "  interW = xB - xA + 1\n",
    "  interH = yB - yA + 1\n",
    "\n",
    "  # Correction: reject non-overlapping boxes\n",
    "  if interW <=0 or interH <=0 :\n",
    "    return 0#-1.0\n",
    "\n",
    "  interArea = interW * interH\n",
    "  boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "  boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "  iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "  return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match multiple boxes\n",
    "def match_multiple_boxes(boxes_target, boxes_predicted):\n",
    "    total_iou = 0\n",
    "    for i in range(len(boxes_target)):\n",
    "        max_iou = 0\n",
    "        for j in range(len(boxes_predicted)):\n",
    "            try: \n",
    "                curr_iou = bbox_iou(boxes_target[i], boxes_predicted[j])\n",
    "                if curr_iou > max_iou:\n",
    "                    max_iou = curr_iou\n",
    "            except IndexError:\n",
    "                pass\n",
    "        total_iou += max_iou\n",
    "    return total_iou/max(len(boxes_target), len(boxes_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir('./data/test_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = pd.read_csv(\"rescaled_data.csv\")\n",
    "boxes = boxes[[\"number\", \"xmin_scaled\", \"ymin_scaled\", \"xmax_scaled\", \"ymax_scaled\"]]\n",
    "test_data = generate_data(image_list, boxes, \"./data/rescaled_png_files/\")\n",
    "test_data = test_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MarginaliaDataset(test_data)\n",
    "val_dl = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = 2  # 1 class (marginalia) + background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model=model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"faster_r_cnn_weights.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "results=[]\n",
    "detection_threshold = 0.1 # the lower, the less we keep\n",
    "model.eval()\n",
    "model.to(device)\n",
    "for images, targets, id in val_dl:    \n",
    "\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    outputs = model(images)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "\n",
    "        boxes = outputs[i]['boxes']\n",
    "        scores = outputs[i]['scores']\n",
    "        labels = outputs[i]['labels']\n",
    "\n",
    "        keep = torchvision.ops.nms(boxes, scores, detection_threshold) # the lower, the less we keep\n",
    "        boxes = boxes[keep]\n",
    "        scores = scores[keep]\n",
    "        image_id = id[i]\n",
    "    \n",
    "        op = (id[i], boxes, scores)\n",
    "        results.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(imageID, tensor_bounding_box):\n",
    "    tensor_bounding_box = tensor_bounding_box.cpu().detach().numpy()\n",
    "    image = cv.imread(f\"data/test_images/{imageID}.png\")\n",
    "    image = np.asarray(image)\n",
    "    for box in tensor_bounding_box:\n",
    "        x_min = box[0]\n",
    "        y_min = box[1]\n",
    "        x_max = box[2]\n",
    "        y_max = box[3]\n",
    "        \n",
    "        color = (0, 0, 255)\n",
    "        start_point = (int(x_min), int(y_min))\n",
    "        end_point = (int(x_max), int(y_max))\n",
    "        thickness = 2\n",
    "        cv.rectangle(image, start_point, end_point, color, thickness)\n",
    "    cv.imwrite(f'./results/prediction_{imageID}.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction_and_target(imageID, tensor_target, tensor_predicted):\n",
    "    tensor_target = tensor_target.cpu().detach().numpy()\n",
    "    tensor_predicted = tensor_predicted.cpu().detach().numpy()\n",
    "\n",
    "    image = cv.imread(f\"data/test_images/{imageID}.png\")\n",
    "    image = np.asarray(image)\n",
    "    for box in tensor_target:\n",
    "        x_min = box[0]\n",
    "        y_min = box[1]\n",
    "        x_max = box[2]\n",
    "        y_max = box[3]\n",
    "        \n",
    "        color = (0, 0, 255) # BLUE: Labeled boxes\n",
    "        start_point = (int(x_min), int(y_min))\n",
    "        end_point = (int(x_max), int(y_max))\n",
    "        thickness = 1\n",
    "        cv.rectangle(image, start_point, end_point, color, thickness)\n",
    "    for box in tensor_predicted:\n",
    "        x_min = box[0]\n",
    "        y_min = box[1]\n",
    "        x_max = box[2]\n",
    "        y_max = box[3]\n",
    "        \n",
    "        color = (255, 0, 0) # red: Predicted boxes\n",
    "        start_point = (int(x_min), int(y_min))\n",
    "        end_point = (int(x_max), int(y_max))\n",
    "        thickness = 1\n",
    "        cv.rectangle(image, start_point, end_point, color, thickness)\n",
    "    cv.imwrite(f'./results/prediction_{imageID}.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Prediction\n",
    "def evaluate_visualize_results():\n",
    "    boxes = pd.read_csv(\"rescaled_data.csv\")\n",
    "    boxes = boxes[[\"number\", \"xmin_scaled\", \"ymin_scaled\", \"xmax_scaled\", \"ymax_scaled\"]]\n",
    "    iou_list = []\n",
    "\n",
    "    for result in results:\n",
    "        id = result[0]\n",
    "        # predicted boxes\n",
    "        predicted_boxes = result[1]\n",
    "        # target boxes\n",
    "        sub_df = boxes[boxes[\"number\"] == int(id)]\n",
    "        num_boxes = len(sub_df)\n",
    "        box_coordinates = []\n",
    "        for i in range(num_boxes):\n",
    "            sub_sub_df = sub_df.iloc[i]\n",
    "            xmin_scaled = int(sub_sub_df[\"xmin_scaled\"])\n",
    "            ymin_scaled = int(sub_sub_df[\"ymin_scaled\"])\n",
    "            xmax_scaled = int(sub_sub_df[\"xmax_scaled\"])\n",
    "            ymax_scaled = int(sub_sub_df[\"ymax_scaled\"])\n",
    "            box_coordinates.append(torch.tensor([xmin_scaled, ymin_scaled, xmax_scaled, ymax_scaled], dtype=torch.int32))\n",
    "        if num_boxes > 1:\n",
    "                target_boxes = torch.stack(box_coordinates, axis=0)\n",
    "        elif num_boxes == 1:\n",
    "            box_coordinates = box_coordinates[0]\n",
    "            target_boxes = box_coordinates.view(1,4)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # evaluate predicted_boxes vs target_boxes\n",
    "        # idxs_true, idxs_pred, ious, labels = match_bboxes(predicted_boxes, target_boxes)\n",
    "        # iou_mean = ious.mean()\n",
    "        iou_mean = match_multiple_boxes(predicted_boxes, target_boxes) # TODO: Which evaluation function?\n",
    "        iou_list.append(iou_mean)\n",
    "\n",
    "        # visualize predicted boxes and target boxes\n",
    "        visualize_prediction_and_target(id, target_boxes, predicted_boxes)\n",
    "\n",
    "    # calculate iou accross all results\n",
    "    iou = sum(iou_list) / len(iou_list)\n",
    "    return iou.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.773455023765564"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_visualize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
