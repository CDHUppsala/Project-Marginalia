{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2 as cv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import math\n",
    "\n",
    "from __future__ import division\n",
    "import scipy.optimize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginaliaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.n_samples = len(data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index][\"data\"]\n",
    "        boxes = self.data[index][\"boxes\"]\n",
    "        labels = self.data[index][\"labels\"]\n",
    "        id = self.data[index][\"image_id\"]\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        return img, target, id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(imageID, path):\n",
    "    \"\"\"reads in image and returns preprocessed np array\"\"\"\n",
    "    img = cv.imread(f\"{path}{imageID}.png\")\n",
    "   # img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    img = img/255\n",
    "    img = torch.tensor(img, dtype=torch.float32)\n",
    "    img = img.permute(2,0,1) # change channel position\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(image_list, box_df, image_path=\"./data/rescaled_png_files/\"):\n",
    "    data = []\n",
    "    all_box_coordinates = []\n",
    "    #print(image_list)\n",
    "    for image in image_list:\n",
    "        image_dict = {}\n",
    "        #id = image.removesuffix('.png') \n",
    "        if image.endswith(\".png\"): \n",
    "            id = image[:-4]\n",
    "        else: \n",
    "            continue\n",
    "\n",
    "        sub_df = box_df[box_df[\"number\"] == int(id)]\n",
    "        num_boxes = len(sub_df)\n",
    "        box_coordinates = []\n",
    "        for i in range(num_boxes):\n",
    "            sub_sub_df = sub_df.iloc[i]\n",
    "            xmin_scaled = int(sub_sub_df[\"xmin_scaled\"])\n",
    "            ymin_scaled = int(sub_sub_df[\"ymin_scaled\"])\n",
    "            xmax_scaled = int(sub_sub_df[\"xmax_scaled\"])\n",
    "            ymax_scaled = int(sub_sub_df[\"ymax_scaled\"])\n",
    "            box_coordinates.append(torch.tensor([xmin_scaled, ymin_scaled, xmax_scaled, ymax_scaled], dtype=torch.int32))\n",
    "        if num_boxes > 1:\n",
    "            box_coordinates = torch.stack(box_coordinates, axis=0)\n",
    "        elif num_boxes == 1:\n",
    "            box_coordinates = box_coordinates[0]\n",
    "            box_coordinates = box_coordinates.view(1,4)\n",
    "        else:\n",
    "            pass\n",
    "        all_box_coordinates.append(box_coordinates)\n",
    "        \n",
    "        image_data = preprocessing(id, image_path) # returns list\n",
    "\n",
    "        # labels\n",
    "        labels = torch.ones(num_boxes, dtype=torch.int64)\n",
    "\n",
    "        # stack it to dict\n",
    "        image_dict[\"data\"] = image_data\n",
    "        image_dict[\"boxes\"] = box_coordinates\n",
    "        image_dict[\"labels\"] = labels\n",
    "        image_dict[\"image_id\"] = id\n",
    "\n",
    "        data.append(image_dict)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from https://gist.github.com/AruniRC/c629c2df0e68e23aff7dcaeef87c72d4\n",
    "\n",
    "def bbox_iou(boxA, boxB):\n",
    "  # https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "  # ^^ corrected.\n",
    "    \n",
    "  # Determine the (x, y)-coordinates of the intersection rectangle\n",
    "  xA = max(boxA[0], boxB[0])\n",
    "  yA = max(boxA[1], boxB[1])\n",
    "  xB = min(boxA[2], boxB[2])\n",
    "  yB = min(boxA[3], boxB[3])\n",
    "\n",
    "  interW = xB - xA + 1\n",
    "  interH = yB - yA + 1\n",
    "\n",
    "  # Correction: reject non-overlapping boxes\n",
    "  if interW <=0 or interH <=0 :\n",
    "    return -1.0\n",
    "\n",
    "  interArea = interW * interH\n",
    "  boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "  boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "  iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "  return iou\n",
    "\n",
    "\n",
    "\n",
    "def match_bboxes(bbox_gt, bbox_pred, IOU_THRESH=0.5):\n",
    "    '''\n",
    "    Given sets of true and predicted bounding-boxes,\n",
    "    determine the best possible match.\n",
    "    Parameters\n",
    "    ----------\n",
    "    bbox_gt, bbox_pred : N1x4 and N2x4 np array of bboxes [x1,y1,x2,y2]. \n",
    "      The number of bboxes, N1 and N2, need not be the same.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (idxs_true, idxs_pred, ious, labels)\n",
    "        idxs_true, idxs_pred : indices into gt and pred for matches\n",
    "        ious : corresponding IOU value of each match\n",
    "        labels: vector of 0/1 values for the list of detections\n",
    "    '''\n",
    "    n_true = bbox_gt.shape[0]\n",
    "    n_pred = bbox_pred.shape[0]\n",
    "    MAX_DIST = 1.0\n",
    "    MIN_IOU = 0.0\n",
    "\n",
    "    # NUM_GT x NUM_PRED\n",
    "    iou_matrix = np.zeros((n_true, n_pred))\n",
    "    for i in range(n_true):\n",
    "        for j in range(n_pred):\n",
    "            iou_matrix[i, j] = bbox_iou(bbox_gt[i,:], bbox_pred[j,:])\n",
    "\n",
    "    if n_pred > n_true:\n",
    "      # there are more predictions than ground-truth - add dummy rows\n",
    "      diff = n_pred - n_true\n",
    "      iou_matrix = np.concatenate( (iou_matrix, \n",
    "                                    np.full((diff, n_pred), MIN_IOU)), \n",
    "                                  axis=0)\n",
    "\n",
    "    if n_true > n_pred:\n",
    "      # more ground-truth than predictions - add dummy columns\n",
    "      diff = n_true - n_pred\n",
    "      iou_matrix = np.concatenate( (iou_matrix, \n",
    "                                    np.full((n_true, diff), MIN_IOU)), \n",
    "                                  axis=1)\n",
    "\n",
    "    # call the Hungarian matching\n",
    "    idxs_true, idxs_pred = scipy.optimize.linear_sum_assignment(1 - iou_matrix)\n",
    "\n",
    "    if (not idxs_true.size) or (not idxs_pred.size):\n",
    "        ious = np.array([])\n",
    "    else:\n",
    "        ious = iou_matrix[idxs_true, idxs_pred]\n",
    "\n",
    "    # remove dummy assignments\n",
    "    sel_pred = idxs_pred<n_pred\n",
    "    idx_pred_actual = idxs_pred[sel_pred] \n",
    "    idx_gt_actual = idxs_true[sel_pred]\n",
    "    ious_actual = iou_matrix[idx_gt_actual, idx_pred_actual]\n",
    "    sel_valid = (ious_actual > IOU_THRESH)\n",
    "    label = sel_valid.astype(int)\n",
    "\n",
    "    return idx_gt_actual[sel_valid], idx_pred_actual[sel_valid], ious_actual[sel_valid], label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxa = np.array([1,2,3,4])\n",
    "boxb = np.array([1,1,3,4])\n",
    "\n",
    "bbox_iou(boxa, boxb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir('./data/test_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = pd.read_csv(\"rescaled_data.csv\")\n",
    "boxes = boxes[[\"number\", \"xmin_scaled\", \"ymin_scaled\", \"xmax_scaled\", \"ymax_scaled\"]]\n",
    "test_data = generate_data(image_list, boxes, \"./data/rescaled_png_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MarginaliaDataset(test_data)\n",
    "val_dl = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, pin_memory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = 2  # 1 class (marginalia) + background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model=model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"faster_r_cnn_weights.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "results=[]\n",
    "detection_threshold = 0.1 # the lower, the less we keep\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "for images, targets, id in val_dl:    \n",
    "\n",
    "    images = list(image.to(device) for image in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    outputs = model(images)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "\n",
    "        boxes = outputs[i]['boxes']\n",
    "        scores = outputs[i]['scores']\n",
    "        labels = outputs[i]['labels']\n",
    "\n",
    "        keep = torchvision.ops.nms(boxes, scores, detection_threshold) # the lower, the less we keep\n",
    "        boxes = boxes[keep]\n",
    "        scores = scores[keep]\n",
    "        image_id = id[i]\n",
    "    \n",
    "        op = (id[i], boxes, scores)\n",
    "        results.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(imageID, tensor_bounding_box):\n",
    "    tensor_bounding_box = tensor_bounding_box.cpu().detach().numpy()\n",
    "    image = cv.imread(f\"data/test_images/{imageID}.png\")\n",
    "    image = np.asarray(image)\n",
    "    for box in tensor_bounding_box:\n",
    "        x_min = box[0]\n",
    "        y_min = box[1]\n",
    "        x_max = box[2]\n",
    "        y_max = box[3]\n",
    "        \n",
    "        color = (0, 0, 255)\n",
    "        start_point = (int(x_min), int(y_min))\n",
    "        end_point = (int(x_max), int(y_max))\n",
    "        thickness = 2\n",
    "        cv.rectangle(image, start_point, end_point, color, thickness)\n",
    "    cv.imwrite(f'./results/prediction_{imageID}.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction_and_target(imageID, tensor_target, tensor_predicted):\n",
    "    tensor_target = tensor_target.cpu().detach().numpy()\n",
    "    tensor_predicted = tensor_predicted.cpu().detach().numpy()\n",
    "\n",
    "    image = cv.imread(f\"data/test_images/{imageID}.png\")\n",
    "    image = np.asarray(image)\n",
    "    for box in tensor_target:\n",
    "        x_min = box[0]\n",
    "        y_min = box[1]\n",
    "        x_max = box[2]\n",
    "        y_max = box[3]\n",
    "        \n",
    "        color = (0, 0, 255) # BLUE: Labeled boxes\n",
    "        start_point = (int(x_min), int(y_min))\n",
    "        end_point = (int(x_max), int(y_max))\n",
    "        thickness = 1\n",
    "        cv.rectangle(image, start_point, end_point, color, thickness)\n",
    "    for box in tensor_predicted:\n",
    "        x_min = box[0]\n",
    "        y_min = box[1]\n",
    "        x_max = box[2]\n",
    "        y_max = box[3]\n",
    "        \n",
    "        color = (255, 0, 0) # red: Predicted boxes\n",
    "        start_point = (int(x_min), int(y_min))\n",
    "        end_point = (int(x_max), int(y_max))\n",
    "        thickness = 1\n",
    "        cv.rectangle(image, start_point, end_point, color, thickness)\n",
    "    cv.imwrite(f'./results/prediction_{imageID}.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Prediction\n",
    "def evaluate_visualize_results():\n",
    "    boxes = pd.read_csv(\"rescaled_data.csv\")\n",
    "    boxes = boxes[[\"number\", \"xmin_scaled\", \"ymin_scaled\", \"xmax_scaled\", \"ymax_scaled\"]]\n",
    "    iou_list = []\n",
    "\n",
    "    for result in results:\n",
    "        id = result[0]\n",
    "        # predicted boxes\n",
    "        predicted_boxes = result[1]\n",
    "        # target boxes\n",
    "        sub_df = boxes[boxes[\"number\"] == int(id)]\n",
    "        num_boxes = len(sub_df)\n",
    "        box_coordinates = []\n",
    "        for i in range(num_boxes):\n",
    "            sub_sub_df = sub_df.iloc[i]\n",
    "            xmin_scaled = int(sub_sub_df[\"xmin_scaled\"])\n",
    "            ymin_scaled = int(sub_sub_df[\"ymin_scaled\"])\n",
    "            xmax_scaled = int(sub_sub_df[\"xmax_scaled\"])\n",
    "            ymax_scaled = int(sub_sub_df[\"ymax_scaled\"])\n",
    "            box_coordinates.append(torch.tensor([xmin_scaled, ymin_scaled, xmax_scaled, ymax_scaled], dtype=torch.int32))\n",
    "        if num_boxes > 1:\n",
    "                target_boxes = torch.stack(box_coordinates, axis=0)\n",
    "        elif num_boxes == 1:\n",
    "            box_coordinates = box_coordinates[0]\n",
    "            target_boxes = box_coordinates.view(1,4)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # evaluate predicted_boxes vs target_boxes\n",
    "        idxs_true, idxs_pred, ious, labels = match_bboxes(predicted_boxes, target_boxes)\n",
    "        iou_mean = ious.mean()\n",
    "        iou_list.append(iou_mean)\n",
    "\n",
    "        # visualize predicted boxes and target boxes\n",
    "        visualize_prediction_and_target(id, target_boxes, predicted_boxes)\n",
    "\n",
    "    # calculate iou accross all results\n",
    "    iou = sum(iou_list) / len(iou_list)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.900658767024676"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_visualize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
