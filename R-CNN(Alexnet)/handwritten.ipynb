{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -- coding: utf-8 --\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import splitfolders\n",
    "from torch import nn, optim\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "photo_path = '/Users/imchengliang/Downloads/DS-Project/photo/'\n",
    "train_path = '/Users/imchengliang/Downloads/DS-Project/b_w_image/'\n",
    "json_path = '/Users/imchengliang/Downloads/DS-Project/json-data/'\n",
    "train_path = '/Users/imchengliang/Downloads/DS-Project/b_w_image/'\n",
    "data_path = '/Users/imchengliang/Downloads/DS-Project/data/'\n",
    "data_path_1 = '/Users/imchengliang/Downloads/DS-Project/train_0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save coordinate data into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_df():\n",
    "    file_list = sorted(os.listdir(json_path))\n",
    "    info_list = []\n",
    "    for f in file_list:\n",
    "        path = json_path + '/' + f\n",
    "        p = f.split(\".\")\n",
    "        p_path = photo_path + p[0] + '.png'\n",
    "        with open(path) as data:\n",
    "            dict1 =  json.load(data)\n",
    "            for i in range(len(dict1['shapes'])):\n",
    "                info = {}\n",
    "                info['number'] = p[0]\n",
    "                info['jsonname'] = path\n",
    "                info['photoname'] = p_path\n",
    "                info['width'] = dict1['imageWidth']\n",
    "                info['height'] = dict1['imageHeight']\n",
    "                info['class'] = dict1['shapes'][i]['label']\n",
    "                info['xmin'] = dict1['shapes'][i]['points'][0][0]\n",
    "                info['ymin'] = dict1['shapes'][i]['points'][0][1]\n",
    "                info['xmax'] = dict1['shapes'][i]['points'][1][0]\n",
    "                info['ymax'] = dict1['shapes'][i]['points'][1][1]\n",
    "                info_list.append(info)\n",
    "    return pd.DataFrame(info_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1708, 10)\n"
     ]
    }
   ],
   "source": [
    "df_train = generate_train_df()\n",
    "df_train.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch the image into black and white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path):\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # binary conversions\n",
    "    ret, threshold = cv2.threshold(gray, 160, 255, cv2.THRESH_BINARY)\n",
    "    #kernel = np.ones((2, 2), np.uint8)\n",
    "    # morphological operations:\n",
    "    #erosion = cv2.erode(threshold, kernel, iterations = 1)\n",
    "    #dilation = cv2.dilate(threshold, kernel,iterations = 1)\n",
    "    #opening = cv2.morphologyEx(threshold, cv2.MORPH_OPEN, kernel)\n",
    "    #closing = cv2.morphologyEx(threshold, cv2.MORPH_CLOSE, kernel)\n",
    "    # rescale the size\n",
    "    #new_width  = 700\n",
    "    #new_height = 1000\n",
    "    #resized_image = cv2.resize(threshold, (new_width, new_height))\n",
    "    #cv2.imshow(\"cvtColor2gray\", closing)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    #plt.imshow(closing, 'gray')\n",
    "    #plt.show()\n",
    "    a = path.split('/')[-1]\n",
    "    cv2.imwrite('/Users/imchengliang/Downloads/DS-Project/b_w_image/'+a, threshold, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = sorted(os.listdir(photo_path))\n",
    "for i in file_list:\n",
    "    preprocess('/Users/imchengliang/Downloads/DS-Project/photo/'+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './train/train_image'\n",
    "test_dir = './test/test_image'\n",
    "image_dir = './b_w_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = sorted(os.listdir(image_dir))\n",
    "random.seed(42)\n",
    "random.shuffle(file_list)\n",
    "num_samples = len(file_list)\n",
    "train_size = 0.9\n",
    "train_data = file_list[0:math.ceil(train_size*num_samples)]\n",
    "test_data = file_list[math.ceil(train_size*num_samples):]\n",
    "\n",
    "for i in train_data:\n",
    "    shutil.copy(image_dir+'/'+i, train_dir+'/'+i)\n",
    "for i in test_data:\n",
    "    shutil.copy(image_dir+'/'+i, test_dir+'/'+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the coordination data into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_coord(id, name):\n",
    "    file = pd.read_csv('data.csv')\n",
    "    #id = file['number'].unique()\n",
    "    coordinates = {}\n",
    "    for j in id:\n",
    "        i = j.split('.')[0]\n",
    "        a = file.loc[file['number']==int(i)]\n",
    "        coordinate = []\n",
    "        for index, row in a.iterrows():\n",
    "            b = []\n",
    "            b.append(row['xmin'])\n",
    "            b.append(row['ymin'])\n",
    "            b.append(row['xmax'])\n",
    "            b.append(row['ymax'])\n",
    "            #b.append(row['class'])\n",
    "            coordinate.append(b)\n",
    "        coordinates[int(i)] = coordinate\n",
    "\n",
    "    with open(name, 'w') as f:\n",
    "        json.dump(coordinates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = sorted(os.listdir(train_dir))\n",
    "test_id = sorted(os.listdir(test_dir))\n",
    "train_name = 'train_coordinates.json'\n",
    "test_name = 'test_coordinates.json'\n",
    "save_coord(train_id, train_name)\n",
    "save_coord(test_id, test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_coordinates.json') as f:\n",
    "    train_coordinates = json.load(f)\n",
    "\n",
    "with open('test_coordinates.json') as f:\n",
    "    test_coordinates = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut the handwritten part and save its shape information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_handwritten(t_coordinates, file, path1, path2):\n",
    "    cut_shape = {}\n",
    "    for i in t_coordinates.keys():\n",
    "        print(i)\n",
    "        img_path = path1+'/'+str(i)+'.png'\n",
    "        im = cv2.imread(img_path)\n",
    "        a = 1\n",
    "        for j in t_coordinates[i]:\n",
    "            name = str(i)+'_'+str(a)\n",
    "            # y first, x second\n",
    "            ims = im[math.ceil(j[1]):math.ceil(j[3]), math.ceil(j[0]):math.ceil(j[2])]\n",
    "            cut_shape[name] = [ims.shape[0], ims.shape[1]]\n",
    "            cv2.imwrite(path2+str(i)+'_'+str(a)+'.png', ims)\n",
    "            a += 1\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(cut_shape, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cut_dir = './train/train_cut/'\n",
    "test_cut_dir = './test/test_cut/'\n",
    "cut_handwritten(train_coordinates, 'train_cut_shape.json', train_dir, train_cut_dir)\n",
    "cut_handwritten(test_coordinates, 'test_cut_shape.json', test_dir, test_cut_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_cut_shape.json') as f:\n",
    "    train_cut_shape = json.load(f)\n",
    "\n",
    "with open('test_cut_shape.json') as f:\n",
    "    test_cut_shape = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut and reshape the handwritten part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_data(path1, path2, j):\n",
    "    img = cv2.imread(path1+j+'.png')\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    if (opening.shape[0]>=opening.shape[1] and (opening.shape[0]/opening.shape[1])<=2.07) or (opening.shape[0]<=opening.shape[1] and (opening.shape[1]/opening.shape[0])<=2.07):\n",
    "        resized_image = cv2.resize(opening, (227, 227))\n",
    "        cv2.imwrite(path2+j+'_'+'.png', resized_image)\n",
    "    elif opening.shape[0]>opening.shape[1] and (opening.shape[0]/opening.shape[1])>2.07:\n",
    "        n = int(opening.shape[0] / opening.shape[1])\n",
    "        dis_h = int(np.floor(opening.shape[0] / n))\n",
    "        for i in range(n):\n",
    "            a = i+1\n",
    "            sub = opening[i*dis_h:(i+1)*dis_h, 0:opening.shape[1]]\n",
    "            resized_image = cv2.resize(sub, (227, 227))\n",
    "            cv2.imwrite(path2+j+'_'+str(a)+'.png', resized_image)\n",
    "    elif opening.shape[0]<opening.shape[1] and (opening.shape[1]/opening.shape[0])>2.07:\n",
    "        n = int(opening.shape[1] / opening.shape[0])\n",
    "        dis_w = int(np.floor(opening.shape[1] / n))\n",
    "        for i in range(n):\n",
    "            a = i+1\n",
    "            sub = opening[0:opening.shape[0], i*dis_w:(i+1)*dis_w]\n",
    "            resized_image = cv2.resize(sub, (227, 227))\n",
    "            cv2.imwrite(path2+j+'_'+str(a)+'.png', resized_image)\n",
    "    print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1_dir = './train/train_1/'\n",
    "test_1_dir = './test/test_1/'\n",
    "\n",
    "for j in train_cut_shape.keys():\n",
    "    pre_data(train_cut_dir, train_1_dir, j)\n",
    "\n",
    "for j in test_cut_shape.keys():\n",
    "    pre_data(test_cut_dir, test_1_dir, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the maximum and minium of box size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528.0 41.176470588235304 3703.703703703703 33.33333333333337 7492408.329560887 1614.7635524798125\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv('data.csv')\n",
    "x, y, xy = [], [], []\n",
    "for i in range(len(file['number'])):\n",
    "    x.append(file['xmax'][i]-file['xmin'][i])\n",
    "    y.append(file['ymax'][i]-file['ymin'][i])\n",
    "    xy.append((file['xmax'][i]-file['xmin'][i])*(file['ymax'][i]-file['ymin'][i]))\n",
    "print(max(x), min(x), max(y), min(y), max(xy), min(xy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "752579dbebe7f4dfe7c1aa72eac13e23fc88be2cc1ea7ab14e1f8d69b2d97d12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
